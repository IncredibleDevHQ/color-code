const express = require('express')
const app = express()
const port = 3000

const express = require("express");
const fs = require('fs');
const path = require('path');
const vsctm = require('../release/main');
const oniguruma = require('oniguruma');
const themedTokenize = require('../out/tests/themedTokenizerCustom');
const main = require('../out/main');

app.get('/', (req, res) => {
	  res.send('Hello World!')
})

app.listen(port, () => {
	  console.log(`Example app listening at http://localhost:${port}`)
})

app.post("/javascript", (req, res) => {
	console.log("test ..here 1")
	//await producer.connect()
	console.log(req.body)
	var code = req.body.code 
        var theme = req.body.theme
	var language = req.body.language
	console.log(code)
	// Create a registry that can create a grammar from a scope name.
	const registry = new vsctm.Registry({
		    onigLib: Promise.resolve({
			createOnigScanner: (sources) => new oniguruma.OnigScanner(sources),
			createOnigString: (str) => new oniguruma.OnigString(str)
		}),
		loadGrammar: (scopeName) => {
			if (scopeName === 'source.js') {
				// https://github.com/textmate/javascript.tmbundle/blob/master/Syntaxes/JavaScript.plist
				return readFile('../JavaScript.plist').then(data => vsctm.parseRawGrammar(data.toString()))
			}
			console.log(`Unknown scope name: ${scopeName}`);
			return null;
		}
	});
	
	registry.setTheme(readTheme(theme));
	// Load the JavaScript grammar and any other grammars included by it async.
	registry.loadGrammar('source.js').then(async(grammar) => {
		const text = code
		console.log(themedTokenize.tokenizeWithThemeLine(registry.getColorMap(), text, grammar));
		/*
		let ruleStack = vsctm.INITIAL;
		for (let i = 0; i < text.length; i++) {
			const line = text[i];
			const lineTokens = grammar.tokenizeLine(line, ruleStack);
			console.log(`\nTokenizing line: ${line}`);
			for (let j = 0; j < lineTokens.tokens.length; j++) {
				const token = lineTokens.tokens[j];
				console.log(` - token from ${token.startIndex} to ${token.endIndex} ` +
					    `(${line.substring(token.startIndex, token.endIndex)}) ` +
					    `with scopes ${token.scopes.join(', ')}`
				);
			}
			ruleStack = lineTokens.ruleStack;
		}*/
		res.send(themedTokenize.tokenizeWithThemeLine(registry.getColorMap(), text, grammar))
	/* 
		await producer.send({
			topic: 'color',
			messages: [
			    	    {
			        	key: 'my-key',
					value: JSON.stringify(themedTokenize.tokenizeWithThemeLine(registry.getColorMap(), text, grammar)),
				    }
			],
		})*/
	}); 
        //await producer.disconnect()
});
